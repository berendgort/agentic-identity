# Berend Gort

## ML & Research Engineer | Agent Systems & LLM Evaluation | PhD AI

**Location:** Barcelona, Catalonia, Spain  
**Email:** berendgorths@gmail.com  
**LinkedIn:** www.linkedin.com/in/bjdg  
**Followers:** 942 | **Connections:** 500+

---

## About

I'm a PhD Candidate and ML Engineer working on agent systems and LLM evaluation.

I build production ML infrastructure that scales and publish research on how to make AI agents more reliable. My work combines evaluation frameworks that measure agent capabilities with systems that deploy these models in production.

**Recent highlights:**
- AgentEdge framework: 2.76Ã— improvement in multi-agent orchestration
- Production inference with NVIDIA Triton, Kubernetes, and MLOps
- Custom evaluation frameworks for LLM tool use and reasoning
- Model optimization: 67% latency reduction, 13% energy savings
- 5+ publications on transformers and agent systems

Currently finishing my PhD in AI at Universitat PolitÃ¨cnica de Catalunya while exploring safer agent systems through evaluation and testing.

I contribute to open source and write about what I learn. Let's connect if you're working on similar problems.

---

## Experience

### AI Research Engineer
**Nearby Computing** Â· Full-time  
**Mar 2023 - Present** Â· 2 yrs 8 mos  
**Location:** Barcelona, Catalonia, Spain Â· Hybrid

âž¢ Built AgentOne multi-MCP agentic orchestration system for autonomous infrastructure management
âž¢ Architected production MCP server for LLM tool-use abstracting APIs and reducing complexity  
âž¢ Developed AgentEdge LLM-powered multi-agent framework with 2.76Ã— higher success rates  
âž¢ Created AERO lightweight model for LLM inference reducing latency by 67% and energy use by 13%  
âž¢ Built OmniFORE transformer framework improving accuracy by 69% and inference speed by 17%  
âž¢ Designed ActSimCrit agent planning methodology using digital twins for safe orchestration decisions  
âž¢ Secured MareNostrum 5 HPC allocation for large-scale transformer model training and optimization  
âž¢ Engineered high-performance REST API enabling real-time agent orchestration at production scale  
âž¢ Deployed production MLOps platform achieving 99.99% uptime with MLflow and Kubernetes  
âž¢ Built LLM inference pipeline scaling to 425 inferences per second using NVIDIA Triton  
âž¢ Optimized transformer model performance by 38.45Ã— through Bayesian hyperparameter tuning  
âž¢ Led 5-person engineering team building LLM-powered autonomous agent orchestration systems

**Skills:** PyTorch Â· Large Language Models (LLM) Â· Agents Â· Multi-agent Systems Â· NVIDIA Triton Â· Transformers Â· Kubernetes Â· Natural Language Processing (NLP) Â· Artificial Intelligence (AI) Â· Python (Programming Language) Â· Docker Â· Deep Learning Â· Machine Learning Â· Distributed Systems Â· MLOps

**Associated Publications:**
- AERO: Adaptive Edge-Cloud Orchestration with a Sub-1K-Parameter Forecasting Model
- Attention-Driven AI Model Generalization for Workload Forecasting in the Compute Continuum

---

### AI Research Engineer
**Columbia University in the City of New York** Â· Full-time  
**Jan 2022 - Dec 2022** Â· 1 yr  
**Location:** New York, United States Â· Remote

âž¢ Presented AAAI'23 poster on deep RL reducing backtest overfitting by 46%  
âž¢ Grew FinRL open-source project GitHub engagement by 214% moderating contributions  
âž¢ Led team deploying scalable ML pipelines using Docker and Kubernetes for big data  
âž¢ Reached 10,000 followers through technical articles on ML systems and optimization

**Skills:** Artificial Intelligence (AI) Â· Containerization Â· Linux Â· Machine Learning Â· Deep Learning Â· Large Language Models (LLM) Â· Google Cloud Platform (GCP) Â· Problem Solving Â· PyTorch Â· Deep Reinforcement Learning Â· Docker Â· Kubernetes Â· Google Cloud Â· Git Â· MLOps

**Associated Publication:**
- Deep Reinforcement Learning for Cryptocurrency Trading: Practical Approach to Address Backtest Overfitting

---

### AI Robotics Research Engineer
**TNO** Â· Internship  
**Jun 2019 - Jun 2020** Â· 1 yr 1 mo  
**Location:** Delft Area, Netherlands

âž¢ Reduced control error by 86% through design enhancements in robotic optical terminal  
âž¢ Developed laser communication system for LEO satellites enabling 1+ Tbps speeds  
âž¢ Led cross-functional re-engineering effort reducing robotic terminal costs by 28%

**Skills:** Artificial Intelligence (AI) Â· MATLAB Â· Mathematics Â· Problem Solving Â· Systems Engineering Â· Control Systems Design Â· Robotics

**Associated Project:**
- Laser SATCOM, Space and Scientific Instrumentation

---

### Fusion Robotics Engineer | Scholarship
**Swiss Plasma Center at EPFL** Â· Internship  
**Nov 2018 - Apr 2019** Â· 6 mos  
**Location:** Lausanne Area, Switzerland

âž¢ Redesigned robotic control system reducing control error by 91%  
âž¢ Awarded full internship scholarship by FuseNet for fusion energy research  
âž¢ Collaborated with six physicists and engineers on TCV Fusion Reactor control systems  
âž¢ Developed microwave beam control system directing 4.5MW into plasma for reactor heating

**Skills:** MATLAB Â· Mathematics Â· Problem Solving Â· Systems Engineering Â· Robotics Â· Control Systems Design

---

## Education

### Doctor of Philosophy - PhD, Artificial Intelligence
**Universitat PolitÃ¨cnica de Catalunya**  
**Oct 2023 - Mar 2026**

âž¢ Researching transformer models and attention mechanisms for efficient inference systems  
âž¢ Publishing on agent systems, model compression, and production ML optimization  
âž¢ Developing multi-agent orchestration frameworks with evaluation methodologies  
âž¢ Advancing techniques for safe and reliable LLM-powered autonomous systems

**Skills:** Problem Solving Â· Natural Language Processing (NLP) Â· Mathematics

---

### Master's degree, Engineering in AI & Computer Science
**HARBOUR.SPACE**  
**2020 - 2021**  
**Grade:** Magna Cum Laude, 9.4

âž¢ Graduated magna cum laude with full scholarship for academic excellence  
âž¢ Achieved 10.0/10.0 thesis grade on deep reinforcement learning for sequential decision-making  
âž¢ Coursework highlights: Neural Networks (9.8) â€¢ Deep Learning (9.8) â€¢ Machine Learning (9.5)

**Skills:** Linux Â· Machine Learning Â· Problem Solving Â· Natural Language Processing (NLP) Â· Artificial Intelligence (AI) Â· Java Â· Mathematics Â· C++

---

### Master's degree, Mechanical Engineering
**Eindhoven University of Technology**  
**2018 - 2020**  
**Grade:** 7.3

âž¢ Thesis on torque ripple minimization using repetitive control and optimization algorithms  
âž¢ Specialized in control systems with focus on mathematical modeling and numerical optimization  
âž¢ Top coursework: System Theory (9.0) â€¢ Scientific Computing (8.0) â€¢ Control Engineering (8.0)

**Skills:** Linux Â· Problem Solving Â· Artificial Intelligence (AI) Â· Mathematics Â· MATLAB

---

### Bachelor of Science (BSc), Mechanical Engineering
**Eindhoven University of Technology**  
**2012 - 2017**  
**Grade:** 9.0 (Thesis)

âž¢ Reduced quadcopter propeller noise by 85% through aerodynamic design optimization  
âž¢ Designed and 3D printed universal propeller solution applicable to any quadcopter platform

**Skills:** Problem Solving Â· Mathematics Â· MATLAB

---

### International Baccalaureate
**International Baccalaureate**  
**2008 - 2011**  
**Grade:** International Baccalaureate in English, which is a bilingual education

---

### High School Diploma, Nature & Technics
**Kandinsky College**  
**2006 - 2011**

Took the two most advanced courses in Mathematics of the Dutch Education System:
- Mathematics D
- Mathematics B

---

## Publications

### 1. Optimization of Distinct Time-Series Neural Architectures for Cloud-Edge Workload Prediction
**IEEE Machine Learning for Communication and Networking** Â· Sep 3, 2025

Optimizing resource utilization in cloud-edge networks requires accurate workload prediction under strict computational constraints. Traditional methods like Recurrent Neural Networks (RNNs) struggle to balance accuracy and efficiency in these dynamic environments. In this paper, we evaluate distinct state-of-the-art time-series architectures for containerized workload prediction, including Graph Neural Networks (GNNs), temporal Convolutional Neural Networks (CNNs), Transformers, and sparse Multi-Layer Perceptrons (MLPs). Through empirical analysis using Bayesian optimization, we identify optimal model configurations for cloud-edge workload prediction. Notably, the MLP model achieves comparable memory prediction accuracy to the best CNN model, while using approximately 7,000Ã— less parameters (i.e., 35 vs. 247,091) and 5Ã— faster inference (1.84Âµs vs. 7.15Âµs). Our findings provide concrete guidance for model selection across different cloud-edge deployment scenarios, from resource-constrained edge devices to high-capacity cloud servers.

---

### 2. Attention-Driven AI Model Generalization for Workload Forecasting in the Compute Continuum
**IEEE Transactions on Machine Learning in Communications and Networking** Â· Jun 27, 2025

Effective resource management in edge-cloud networks demands precise forecasting of diverse workload resource usage. Due to the fluctuating nature of user demands, prediction models must have strong generalization abilities, ensuring high performance amidst sudden traffic changes or unfamiliar patterns. Existing approaches often struggle with handling long-term dependencies and the diversity of temporal patterns. This paper introduces OmniFORE (Framework for Optimization of Resource forecasts in Edge-cloud networks), which integrates attention-based time-series models with temporal clustering to enhance generalization and predict diverse workloads efficiently in volatile settings. By training on carefully selected subsets from extensive datasets, OmniFORE captures both short-term stability and long-term shifts in resource usage patterns. Experiments show that OmniFORE outperforms state-of-the-art methods in prediction accuracy, inference speed, and generalization to unseen data, particularly in scenarios with dynamic workload changes and varying trace variance. These improvements enable more efficient resource management in the compute continuum.

---

### 3. AERO: Adaptive Edge-Cloud Orchestration With a Sub-1K-Parameter Forecasting Model
**IEEE Transactions on Machine Learning in Communications and Networking** Â· Mar 1, 2025

Effective resource management in edge-cloud networks is crucial for meeting Quality of Service (QoS) requirements while minimizing operational costs. However, dynamic and fluctuating workloads pose significant challenges for accurate workload prediction and efficient resource allocation, particularly in resource-constrained edge environments. In this paper, we introduce AERO (Adaptive Edge-cloud Resource Orchestration), a novel lightweight forecasting model designed to address these challenges. AERO features an adaptive period detection mechanism that dynamically identifies dominant periodicities in multivariate workload data, allowing it to adjust to varying patterns and abrupt changes. With fewer than 1,000 parameters, AERO is highly suitable for deployment on edge devices with limited computational capacity. We formalize our approach through a comprehensive system model and extend an existing simulation framework with predictor modules to evaluate AERO's performance in realistic cloud-edge environments. Our extensive evaluations on real-world cloud workload datasets demonstrate that AERO achieves comparable prediction accuracy to complex state-of-the-art models with millions of parameters, while significantly reducing model size and computational overhead. In addition, simulations show that AERO improves orchestration performance, reducing energy consumption and response times compared to existing proactive and reactive approaches. Our live deployment experiments further validate these findings, demonstrating that AERO consistently delivers superior performance. These results highlight AERO as an effective solution for improving resource management and reducing operational costs in dynamic cloud-edge environments.

---

### 4. Forecasting Trends in Cloud-Edge Computing: Unleashing the Power of Attention Mechanisms
**IEEE Communications Magazine** Â· Oct 22, 2024

In the face of expanding digital landscapes, cloud-edge computing infrastructures struggle with an ever-increasing demand for real-time data management. This demand has a direct impact on the energy consumption of cloud-edge networks, which has spiked dramatically, stressing the need for accurate time-series forecasting. As conventional machine learning models encounter difficulties in predicting volatile workloads, attention mechanisms have emerged thanks to their capability of capturing long-range dependencies. This article pioneers the exploration of attention mechanisms for time-series forecasting in cloud-edge environments, particularly focusing on a promising low-complexity attention mechanism (i.e., informer model). Through comprehensive discussions and experimental validations, we demonstrate that informers significantly outperform traditional models in the prediction accuracy of compute workload forecasting. The outcome of this work not only highlights the importance of attention mechanisms in cloud-edge scenarios, but also paves the way for future optimizations, ultimately aiming at reducing the environmental impact of digital growth.

---

### 5. Deep Reinforcement Learning for Cryptocurrency Trading: Practical Approach to Address Backtest Overfitting
**Association for the Advancement of Artificial Intelligence (AAAI)** Â· Dec 16, 2022

Designing profitable and reliable trading strategies is challenging in the highly volatile cryptocurrency market. Existing works applied deep reinforcement learning methods and optimistically reported increased profits in backtesting, which may suffer from the false positive issue due to overfitting. In this paper, we propose a practical approach to address backtest overfitting for cryptocurrency trading using deep reinforcement learning. We train different agents, estimate the probability of overfitting, and reject the overfitted agents. We show that the less overfitted agents have higher returns than of more overfitted agents, offering confidence in possible deployment to a real market.

---

## Recommendations

### Angelos Antonopoulos
**Research and Innovation Director at Nearby Computing â€¢ PhD in Telecom â€¢ 5G/6G â€¢ AI/ML â€¢ Edge Computing**  
**Managed Berend directly** Â· October 16, 2025

> "Within our R&I team at Nearby Computing, Berend leads the end-to-end development of our autonomous orchestration stack (MLOps â†’ predictions â†’ agent layer â†’ actions across edge infrastructures). He has implemented AgentEdge (our multi-agent framework), and established custom evaluation methodologies now embedded in our workflow. He also architected a high-throughput inference pipeline that leverages NVIDIA Triton, and continues to optimize the full stack for performance and reliability. Berend's work consistently shows rigor, scalability, and clear end-to-end accountability."

---

### Godfrey Kibalya, PhD
**Nearby Computing**  
**Worked with Berend on the same team** Â· November 13, 2025

> "Berend is an exceptional colleague within the R&I team at Nearby Computing whose clear, empathetic communication and natural mentoring ability consistently elevate the people around him. He takes genuine initiative, stepping up to solve challenges before they surface and guiding others with patience and clarity. Beyond his technical skills and ownership, Berend contributes meaningfully to team culture, fostering collaboration, encouraging open dialogue, and creating an environment where everyone feels supported and motivated."

---

### Xiao-Yang Liu
**PhD, Columbia University in the City of New York**  
**Managed Berend directly** Â· July 13, 2022

> "Berend is a talented programmer and has solid software engineering skills. He has made a substantial contribution to the open-source project FinRL (https://github.com/AI4Finance-Foundation/FinRL). During our collaboration on the project "Addressing backtest overfitting", I enjoyed discussing with him very much! He showed great passion for high tech and was devoted to making intellectual contributions!"

---

### Radoslav Neychev, PhD
**girafe-aiðŸ¦’ founder; Head of ML at Yandex AI Lab**  
**Managed Berend directly** Â· March 31, 2022

> "I am pleased to provide my recommendation for Berend Gort, whom I have known as Machine Learning and Deep Learning lecturer as well as Master's Thesis supervisor.
>
> Berend possesses a sharp mind, strong motivation and perseverance and has achieved remarkable results both in the educational process and in personal research. His Master's Thesis was devoted to RL applications in Cryptocurrency trading. I was glad to see efficient implementation and adaptation of the novel algorithms to the trading process. With the achieved results Berend has defended his Thesis with excellence.
>
> On a personal level, Berend is well disciplined, reliable, committed and curious. He demonstrates both thorough theoretical knowledge and great practical skills. In our interaction he never hesitated to suggest new ideas, ask questions or request feedback and help.
>
> I am glad to leave this recommendation. Good luck!"

---

### Federico Felici
**Research Scientist at Google Deepmind**  
**Managed Berend directly** Â· February 21, 2019

> "Berend worked on a 2-month internship project under my supervision at the Swiss Plasma Center. He applied the knowledge he had gained through his courses on control engineering to design and implement a SISO control loop for a motion system. He applied automated frequency-domain system identification, loop-shaping controller tuning. The system was implemented in Beckhoff TwinCAT3 software, driving a linear servomotor. We were highly satisfied with the result and the team found him very eager, enthusiastic and easy to work with!"

---

## Languages

- **English:** Native or Bilingual
- **Dutch:** Native or Bilingual
- **Spanish:** Professional Working
- **German:** Elementary

---

## Certifications

- International Certificate for Operators of Pleasure Crafts
- Kiteboarder level 3M
- Drivers License (A, motorcycle)
- Spanish B2
- PADI (Rescue Diver)

---

## Honors & Awards

- **Magna Cum Laude** in AI & Computer Science (HARBOUR.SPACE, 2021)
